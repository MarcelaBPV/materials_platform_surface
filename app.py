# app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from supabase import create_client, Client
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split
import ramanchada2 as rc2
import pickle, io

# -------------------------------------------------------
# CONFIGURA√á√ÉO GERAL
# -------------------------------------------------------
st.set_page_config(page_title="Plataforma de Caracteriza√ß√£o", layout="wide")
st.title("üî¨ Plataforma de Caracteriza√ß√£o de Superf√≠cies")

# -------------------------------------------------------
# CONEX√ÉO SUPABASE
# -------------------------------------------------------
@st.cache_resource
def init_connection() -> Client:
    url = st.secrets["SUPABASE_URL"]
    key = st.secrets["SUPABASE_KEY"]
    return create_client(url, key)

supabase = init_connection()

try:
    res = supabase.table("samples").select("*").limit(3).execute()
    st.sidebar.success(f"‚úÖ Conectado ao Supabase ({len(res.data)} amostras encontradas)")
except Exception as e:
    st.sidebar.error(f"Erro ao conectar Supabase: {e}")
    st.stop()

# -------------------------------------------------------
# FUN√á√ïES AUXILIARES
# -------------------------------------------------------
@st.cache_data(ttl=300)
def load_samples():
    data = supabase.table("samples").select("id, sample_name, description, created_at").execute()
    if not data.data:
        return pd.DataFrame(columns=["id", "sample_name", "description", "created_at"])
    return pd.DataFrame(data.data)

def insert_sample(name, desc=None, category_id=None):
    payload = {"sample_name": str(name).strip()}
    if desc and not pd.isna(desc):
        payload["description"] = str(desc)
    if category_id is not None and not pd.isna(category_id):
        try:
            payload["category_id"] = int(category_id)
        except Exception:
            pass
    supabase.table("samples").insert(payload).execute()

def get_measurement_id(sample_id, exp_type):
    meas = supabase.table("measurements").select("id").eq("sample_id", sample_id).eq("type", exp_type).limit(1).execute()
    if meas.data:
        return meas.data[0]["id"]
    new_meas = supabase.table("measurements").insert({"sample_id": sample_id, "type": exp_type}).execute()
    return new_meas.data[0]["id"]

def insert_rows(table, rows):
    if not rows:
        return 0
    supabase.table(table).insert(rows).execute()
    return len(rows)

def read_samples_file(uploaded) -> pd.DataFrame:
    """
    L√™ arquivo de amostras em .csv, .xlsx/.xls ou .txt (tab/;/, autodetect),
    padroniza colunas para: sample_name, description, category_id
    """
    name = uploaded.name.lower()
    if name.endswith(".xlsx") or name.endswith(".xls"):
        df = pd.read_excel(uploaded)
    elif name.endswith(".csv"):
        # autodetect de separador (',' ou ';')
        try:
            df = pd.read_csv(uploaded)
        except Exception:
            df = pd.read_csv(uploaded, sep=";")
    elif name.endswith(".txt"):
        # tenta autodetectar (tab, v√≠rgula, ponto e v√≠rgula)
        try:
            df = pd.read_csv(uploaded, sep=None, engine="python")
        except Exception:
            # fallback comum de arquivos exportados por instrumentos (tab)
            df = pd.read_csv(uploaded, sep="\t", header=0)
    else:
        raise ValueError("Formato n√£o suportado. Use .csv, .xlsx/.xls ou .txt")

    # padroniza nomes de colunas
    df.columns = [c.lower().strip() for c in df.columns]

    # mapeamentos comuns
    colmap = {}
    if "nome" in df.columns and "sample_name" not in df.columns:
        colmap["nome"] = "sample_name"
    if "descricao" in df.columns and "description" not in df.columns:
        colmap["descricao"] = "description"
    if "categoria" in df.columns and "category_id" not in df.columns:
        colmap["categoria"] = "category_id"
    df.rename(columns=colmap, inplace=True)

    # exige sample_name
    if "sample_name" not in df.columns:
        raise ValueError("O arquivo precisa ter a coluna 'sample_name'.")

    # garante colunas opcionais
    if "description" not in df.columns:
        df["description"] = None
    if "category_id" not in df.columns:
        df["category_id"] = None

    # limpa linhas vazias
    df = df[df["sample_name"].astype(str).str.strip() != ""]
    df = df.reset_index(drop=True)
    return df[["sample_name", "description", "category_id"]]

# -------------------------------------------------------
# ABAS
# -------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["1Ô∏è‚É£ Amostras", "2Ô∏è‚É£ Ensaios", "3Ô∏è‚É£ Otimiza√ß√£o (IA)"])

# -------------------------------------------------------
# ABA 1 - AMOSTRAS
# -------------------------------------------------------
with tab1:
    st.header("üìã Cadastro e Visualiza√ß√£o de Amostras")

    df_samples = load_samples()

    # --- Cadastro manual ---
    st.subheader("Cadastrar manualmente")
    new_name = st.text_input("Nome da amostra")
    new_desc = st.text_area("Descri√ß√£o (opcional)")
    if st.button("Cadastrar amostra individual"):
        if new_name:
            insert_sample(new_name, new_desc)
            st.success(f"Amostra '{new_name}' cadastrada com sucesso!")
            df_samples = load_samples()
        else:
            st.warning("Informe um nome de amostra.")

    st.divider()

    # --- Cadastro por arquivo (agora aceita csv/xls/xlsx/txt) ---
    st.subheader("üìÇ Importar lista de amostras (.csv, .xls/.xlsx ou .txt)")
    uploaded = st.file_uploader("Selecione o arquivo de amostras", type=["csv", "xls", "xlsx", "txt"])

    if uploaded:
        try:
            df_new = read_samples_file(uploaded)
            st.write("Pr√©-visualiza√ß√£o:")
            st.dataframe(df_new.head())

            if st.button("Cadastrar amostras em lote"):
                inserted = 0
                for _, row in df_new.iterrows():
                    try:
                        insert_sample(row["sample_name"], row.get("description"), row.get("category_id"))
                        inserted += 1
                    except Exception as e:
                        st.warning(f"Erro ao inserir '{row['sample_name']}': {e}")

                st.success(f"‚úÖ {inserted} amostras cadastradas com sucesso!")
                df_samples = load_samples()

        except Exception as e:
            st.error(f"Erro ao ler arquivo: {e}")

    st.divider()

    # --- Exibir amostras cadastradas ---
    st.subheader("üìã Amostras existentes")
    if df_samples.empty:
        st.info("Nenhuma amostra encontrada.")
    else:
        st.dataframe(df_samples)

# -------------------------------------------------------
# ABA 2 - ENSAIOS (RAMAN, 4 PONTAS, √ÇNGULO)
# -------------------------------------------------------
with tab2:
    st.header("üß™ Processamento de Ensaios")

    df_samples = load_samples()
    sample_options = df_samples["sample_name"].tolist()
    selected_sample = st.selectbox("Escolha a amostra", ["-- Selecione --"] + sample_options)

    if selected_sample != "-- Selecione --":
        sample_id = df_samples.loc[df_samples["sample_name"] == selected_sample, "id"].values[0]
        tipo = st.radio("Tipo de ensaio:", ["Raman", "4 Pontas", "√Çngulo de Contato"])

        uploaded_file = st.file_uploader("Carregar arquivo do ensaio", type=["txt", "csv", "xls", "xlsx"])
        if uploaded_file:
            try:
                if tipo == "Raman":
                    # --- Processamento Raman ---
                    filename = uploaded_file.name.lower()
                    if filename.endswith(".xls") or filename.endswith(".xlsx"):
                        df = pd.read_excel(uploaded_file)
                    elif filename.endswith(".csv"):
                        try:
                            df = pd.read_csv(uploaded_file)
                        except Exception:
                            df = pd.read_csv(uploaded_file, sep=";")
                    elif filename.endswith(".txt"):
                        try:
                            df = pd.read_csv(uploaded_file, sep=None, engine="python")
                        except Exception:
                            df = pd.read_csv(uploaded_file, sep="\t", header=0)
                    else:
                        raise ValueError("Formato n√£o suportado.")

                    df.columns = [c.lower().strip() for c in df.columns]
                    if "wavenumber_cm1" not in df.columns and "wavenumber" in df.columns:
                        df.rename(columns={"wavenumber": "wavenumber_cm1"}, inplace=True)
                    if "intensity_a" not in df.columns and "intensity" in df.columns:
                        df.rename(columns={"intensity": "intensity_a"}, inplace=True)

                    df = df.dropna(subset=["wavenumber_cm1", "intensity_a"])
                    df = df[df["intensity_a"] >= 0]

                    s = rc2.spectrum.from_array(df["wavenumber_cm1"].values, df["intensity_a"].values)
                    s_corr = s.remove_baseline().smooth().normalize()
                    peaks = s_corr.find_peaks(threshold_rel=0.05)

                    st.subheader("üìÑ Dados originais")
                    st.dataframe(df.head())
                    norm_df = pd.DataFrame({"wavenumber_cm1": s_corr.x, "normalized_intensity": s_corr.y})
                    st.subheader("üìà Dados normalizados")
                    st.dataframe(norm_df.head())

                    fig, ax = plt.subplots()
                    s_corr.plot(ax=ax, label="Normalizado")
                    peaks.plot(ax=ax, marker="o", color="r", label="Picos")
                    ax.set_xlabel("N√∫mero de onda (cm‚Åª¬π)")
                    ax.set_ylabel("Intensidade (a.u.)")
                    ax.legend()
                    ax.invert_xaxis()
                    fig.tight_layout()
                    st.pyplot(fig)

                    mid = get_measurement_id(sample_id, "raman")
                    rows = [
                        {"measurement_id": mid, "wavenumber_cm1": float(x), "intensity_a": float(y)}
                        for x, y in zip(s_corr.x, s_corr.y)
                    ]
                    insert_rows("raman_spectra", rows)
                    st.success(f"{len(rows)} pontos Raman importados e normalizados!")

                elif tipo == "4 Pontas":
                    # --- Processamento Resistividade ---
                    # Aceita csv padr√£o; adapte aqui se seus arquivos 4p vierem em xlsx/txt
                    df = pd.read_csv(uploaded_file)
                    df.columns = [c.lower().strip() for c in df.columns]
                    if "current_a" not in df.columns:
                        df.rename(columns={"corrente": "current_a", "i": "current_a"}, inplace=True)
                    if "voltage_v" not in df.columns:
                        df.rename(columns={"tensao": "voltage_v", "v": "voltage_v"}, inplace=True)

                    df = df.dropna(subset=["current_a", "voltage_v"])
                    df = df[(df["current_a"] > 0) & (df["voltage_v"] >= 0)]

                    df["resistance_ohm"] = df["voltage_v"] / df["current_a"]
                    R_med = df["resistance_ohm"].mean()

                    fig, ax = plt.subplots()
                    ax.scatter(df["current_a"], df["voltage_v"], label="Dados experimentais")
                    ax.plot(df["current_a"], df["current_a"] * R_med, "r-", label=f"Ajuste linear (R={R_med:.2f} Œ©)")
                    ax.set_xlabel("Corrente (A)")
                    ax.set_ylabel("Tens√£o (V)")
                    ax.legend()
                    st.pyplot(fig)

                    mid = get_measurement_id(sample_id, "4_pontas")
                    rows = df.to_dict(orient="records")
                    for r in rows:
                        r["measurement_id"] = mid
                    insert_rows("four_point_probe_points", rows)
                    st.success(f"{len(rows)} pontos 4 Pontas cadastrados!")

                elif tipo == "√Çngulo de Contato":
                    # --- Processamento Tensiometria ---
                    # Autodetect de separador para .txt tamb√©m
                    try:
                        df = pd.read_csv(uploaded_file, sep=None, engine="python")
                    except Exception:
                        df = pd.read_csv(uploaded_file, delim_whitespace=True, comment="#")

                    df.columns = [c.lower().strip() for c in df.columns]
                    if "mean" in df.columns and "angle_mean_deg" not in df.columns:
                        df.rename(columns={"mean": "angle_mean_deg"}, inplace=True)
                    if "time" in df.columns and "t_seconds" not in df.columns:
                        df.rename(columns={"time": "t_seconds"}, inplace=True)

                    df = df.dropna(subset=["t_seconds", "angle_mean_deg"])
                    df = df[(df["angle_mean_deg"] >= 0) & (df["angle_mean_deg"] <= 180)]

                    fig, ax = plt.subplots()
                    ax.plot(df["t_seconds"], df["angle_mean_deg"], "bo-", label="√Çngulo de contato")
                    ax.set_xlabel("Tempo (s)")
                    ax.set_ylabel("√Çngulo (¬∞)")
                    ax.legend()
                    st.pyplot(fig)

                    mid = get_measurement_id(sample_id, "tensiometria")
                    rows = df.to_dict(orient="records")
                    for r in rows:
                        r["measurement_id"] = mid
                    insert_rows("contact_angle_points", rows)
                    st.success(f"{len(rows)} pontos de √¢ngulo de contato cadastrados!")

            except Exception as e:
                st.error(f"Erro ao processar arquivo: {e}")

# -------------------------------------------------------
# ABA 3 - OTIMIZA√á√ÉO (IA) - APENAS RAMAN
# -------------------------------------------------------
with tab3:
    st.header("ü§ñ Otimiza√ß√£o via Machine Learning (Random Forest)")
    st.markdown("Treina um modelo IA apenas para **Raman**, aprendendo padr√µes e criando uma assinatura molecular.")

    model_path = "models/raman_model.pkl"

    try:
        data = supabase.table("raman_spectra").select("wavenumber_cm1, intensity_a").execute()
        if not data.data:
            st.warning("Nenhum dado Raman dispon√≠vel.")
            st.stop()

        df = pd.DataFrame(data.data).dropna()
        X = df[["wavenumber_cm1"]].values
        y = df["intensity_a"].values

        # Verifica modelo salvo
        model_exists = False
        try:
            res = supabase.storage.from_("models").download("raman_model.pkl")
            model_file = io.BytesIO(res)
            model = pickle.load(model_file)
            model_exists = True
            st.success("üì¶ Modelo carregado do Supabase Storage!")
        except Exception:
            st.info("Nenhum modelo salvo encontrado. Ser√° treinado um novo.")

        retrain = st.button("üîÅ Re-treinar modelo IA")

        if retrain or not model_exists:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model = RandomForestRegressor(n_estimators=200, random_state=42)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))

            st.success("‚úÖ Modelo Random Forest treinado com sucesso!")
            st.write(f"**R¬≤:** {r2:.3f}")
            st.write(f"**MAE:** {mae:.3f}")
            st.write(f"**RMSE:** {rmse:.3f}")

            buf = io.BytesIO()
            pickle.dump(model, buf)
            buf.seek(0)
            supabase.storage.from_("models").upload("raman_model.pkl", buf, {"content-type": "application/octet-stream"})
            st.info("üíæ Modelo salvo no Supabase Storage!")

        # Previs√£o manual
        st.subheader("üîç Prever intensidade Raman")
        wnum = st.number_input("Digite n√∫mero de onda (cm‚Åª¬π):", min_value=0.0, step=10.0)
        if st.button("Prever intensidade"):
            pred = model.predict(np.array([[wnum]]))[0]
            st.info(f"Intensidade prevista: **{pred:.2f} a.u.**")

        # Identifica√ß√£o molecular
        st.subheader("üî¨ Picos e grupos moleculares")
        known_groups = {
            1000: "Fenilalanina (anel arom√°tico)",
            1250: "Amidas (prote√≠nas)",
            1600: "C=C (lip√≠dios)",
            1650: "Amida I (prote√≠na)"
        }

        detected_peaks = df.loc[df["intensity_a"] > np.percentile(df["intensity_a"], 98), "wavenumber_cm1"].round().unique()
        detected_peaks.sort()
        result_table = []
        for p in detected_peaks:
            group = known_groups.get(int(p), "Desconhecido")
            result_table.append({"Pico (cm‚Åª¬π)": p, "Grupo Molecular": group})

        st.dataframe(pd.DataFrame(result_table))

    except Exception as e:
        st.error(f"Erro na otimiza√ß√£o: {e}")
